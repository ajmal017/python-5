{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning mit Keras\n",
    "\n",
    "Dieses Notebook trainiert mehrere Modell zu den zwei Datensätzen `banknote_authentication.csv` und `spambase.csv`.\n",
    "\n",
    "Zuerst wird der Datensatz `banknote_authentication.csv` betrachtet.\n",
    "\n",
    "##  Spam erkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliotheken einbinden und Daten formatieren**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.activations import relu, elu, sigmoid\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"./spambase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 59)\n"
     ]
    }
   ],
   "source": [
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um später ein Modell mit Keras möglichst effizient darstellen zu können, bietet es sich an die Daten in die Daten selbst und die entsprechenden Lables aufzuteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_new = dat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4456,)\n",
      "(4456, 58)\n"
     ]
    }
   ],
   "source": [
    "train_lables = []\n",
    "train_lables = dat\n",
    "train_lables = dat_new[\"Target\"]\n",
    "train_lables = np.array(train_lables)\n",
    "\n",
    "train_samples = pd.DataFrame([])\n",
    "train_samples = dat_new\n",
    "train_samples = train_samples.drop(['Target'], axis=1)\n",
    "train_samples = np.array(train_samples)\n",
    "\n",
    "\n",
    "print(train_lables.shape)\n",
    "print(train_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Rechenzeit zu verkürzen bietet es sich an, alle Daten innerhalb der oben erstellten `np.arrays` zu skalieren. Dazu bietet das Paket `sklearn` eine super Funktion names `MinMaxScaler`. Sprich alle Daten werden in unserem Fall auf eine Skala von 0 - 1 skaliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)\n",
    "\n",
    "# Zusätzliche Info\n",
    "# Bei 1-D Daten muss man noch diesen Befehl einfügen: .reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4456\n",
      "(4456, 58)\n",
      "(4456,)\n",
      "[1 1 1 ... 0 0 0]\n",
      "[[1.000e+00 0.000e+00 6.400e-01 ... 3.756e+00 6.100e+01 2.780e+02]\n",
      " [2.000e+00 2.100e-01 2.800e-01 ... 5.114e+00 1.010e+02 1.028e+03]\n",
      " [3.000e+00 6.000e-02 0.000e+00 ... 9.821e+00 4.850e+02 2.259e+03]\n",
      " ...\n",
      " [4.599e+03 3.000e-01 0.000e+00 ... 1.404e+00 6.000e+00 1.180e+02]\n",
      " [4.600e+03 9.600e-01 0.000e+00 ... 1.147e+00 5.000e+00 7.800e+01]\n",
      " [4.601e+03 0.000e+00 0.000e+00 ... 1.250e+00 5.000e+00 4.000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(len(scaled_train_samples))\n",
    "len(train_lables)\n",
    "print(scaled_train_samples.shape)\n",
    "print(train_lables.shape)\n",
    "print(train_lables)\n",
    "print(train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modell / Neuronales Netz trainieren:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Talos:**  \n",
    "Talos ist eine Library die es ermöglicht mehrere Parameter auf einmal zu testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers, initializers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'activation':['relu', 'elu'],\n",
    "        'optimizer': ['Nadam', 'Adam'],\n",
    "        'losses': ['logcosh'],\n",
    "        'hidden_layers':[1, 2],\n",
    "        'batch_size': [20,30,40],\n",
    "        'epochs': [10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spambase(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=(58,), activation=params['activation']))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics = ['accuracy'])\n",
    "\n",
    "        out = model.fit(x_train, y_train,\n",
    "                         batch_size=params['batch_size'],\n",
    "                         epochs=params['epochs'],\n",
    "                         validation_data=[x_val, y_val],\n",
    "                         verbose=0)\n",
    "\n",
    "        return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:11<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "\n",
    "scan_object = ta.Scan(scaled_train_samples, train_lables, model=spambase, params=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>losses</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>0.008452</td>\n",
       "      <td>0.987285</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>0.979481</td>\n",
       "      <td>elu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.990277</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.980442</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.988033</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.981084</td>\n",
       "      <td>elu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.982046</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>0.990277</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.983328</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs  val_loss   val_acc      loss       acc activation optimizer  \\\n",
       "42            10  0.008452  0.987285  0.011245  0.979481        elu      Adam   \n",
       "38            10  0.007411  0.990277  0.009918  0.980442       relu      Adam   \n",
       "31            10  0.007933  0.988033  0.010539  0.981084        elu      Adam   \n",
       "8             10  0.007398  0.988781  0.009770  0.982046       relu      Adam   \n",
       "15            10  0.006093  0.990277  0.008171  0.983328       relu      Adam   \n",
       "\n",
       "     losses  hidden_layers  batch_size  epochs  \n",
       "42  logcosh              1          40      10  \n",
       "38  logcosh              2          40      10  \n",
       "31  logcosh              2          40      10  \n",
       "8   logcosh              1          40      10  \n",
       "15  logcosh              2          30      10  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result_spambase = pd.DataFrame(scan_object.data)\n",
    "result_spambase.head()\n",
    "result_spambase.sort_values(by='acc', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebniss:**  \n",
    "Unser Modell ist zwar dermaßen overfitted, dass einem schlecht wird, ABER wir haben eine Genauigkeit bei den Validationdaten von circa 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
